{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp core"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# module name here\n",
    "\n",
    "> API details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "from nbdev.showdoc import *\n",
    "import pandas as pd\n",
    "import logging\n",
    "import datetime\n",
    "import sys\n",
    "import dask.dataframe as dd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir -p tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def test_eq(a,b): assert a==b, f'{a}, {b}'\n",
    "    \n",
    "from collections.abc import Sequence \n",
    "def _seq_but_not_str(obj):\n",
    "    return isinstance(obj, Sequence) and not isinstance(obj, (str, bytes, bytearray))\n",
    "\n",
    "def listify(obj):\n",
    "    if _seq_but_not_str(obj):\n",
    "        return obj\n",
    "\n",
    "    return [obj]\n",
    "    \n",
    "def test_in(items, target):\n",
    "    items = listify(items)\n",
    "    missing = [item for item in items if item not in target]\n",
    "    assert len(missing) == 0, f'{missing} are not in {target}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_in('a', ['a', 'b', 'c'])\n",
    "test_in(['b', 'c'], ['a', 'b', 'c'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def configure_logging(log_dir, log_name, log_lvl='DEBUG', con_log_lvl='INFO'):\n",
    "    log = logging.getLogger('root')\n",
    "    already_initialized = any(filter(lambda h: isinstance(h, logging.StreamHandler), log.handlers))\n",
    "    if already_initialized:\n",
    "        print(\"Logging already initialized\")\n",
    "        return logging.getLogger('root')\n",
    "\n",
    "    numeric_level = getattr(logging, log_lvl, None)\n",
    "    log_format = '%(levelname)5s [%(asctime)s] %(name)s: %(message)s'\n",
    "    date_format = '%Y-%m-%d %H:%M:%S'\n",
    "    logging.basicConfig(\n",
    "        filename=f'{log_dir}/{log_name}_{datetime.datetime.now().strftime(\"%Y-%m-%d_%H_%M_%S\")}.txt',\n",
    "        level=numeric_level,\n",
    "        format=log_format,\n",
    "        datefmt=date_format)\n",
    "    log = logging.getLogger('root')\n",
    "    ch = logging.StreamHandler()\n",
    "    ch.setLevel(getattr(logging, con_log_lvl, None))\n",
    "    ch.setFormatter(logging.Formatter(log_format, date_format))\n",
    "    log.addHandler(ch)\n",
    "\n",
    "    return log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def setup_dataframe_copy_logging(log):\n",
    "    if not '_original_copy' in dir(pd.DataFrame):\n",
    "        log.debug('Patching up DataFrame.copy')\n",
    "        pd.DataFrame._original_copy = pd.DataFrame.copy\n",
    "    else:\n",
    "        log.debug('Patching up DataFrame.copy :: already done - skipping.')\n",
    "\n",
    "    def _loud_copy(self, deep=True):\n",
    "        log.debug(f'Copying {sys.getsizeof(self) / 1024 / 1024:.1f} MiB (deep={deep})')\n",
    "        return pd.DataFrame._original_copy(self, deep)\n",
    "\n",
    "    pd.DataFrame.copy = _loud_copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG [2020-07-06 11:02:57] root: Patching up DataFrame.copy :: already done - skipping.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logging already initialized\n"
     ]
    }
   ],
   "source": [
    "log = configure_logging('./tmp', 'test_log', con_log_lvl='DEBUG')\n",
    "setup_dataframe_copy_logging(log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG [2020-07-06 11:02:57] root: Copying 0.0 MiB (deep=True)\n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame({'a':[1,2,3]})\n",
    "df2 = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "n_total_series = 30490\n",
    "n_days_total = 1913\n",
    "raw_dir = 'raw'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def read_series_sample(log, n):\n",
    "    df = dd.read_csv(\n",
    "        f'{raw_dir}/sales_train_validation.csv'\n",
    "    ).sample(frac = n / n_total_series)\n",
    "    log.debug(f\"Read {len(df)} series\")\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG [2020-07-06 11:03:04] root: Read 13 series\n"
     ]
    }
   ],
   "source": [
    "sample = read_series_sample(log, 13)\n",
    "test_eq(13, len(sample))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def melt_sales_series(df_sales_train):\n",
    "    id_columns = [col for col in df_sales_train.columns if 'id' in col]\n",
    "    sales_columns = [col for col in df_sales_train.columns if 'd_' in col]\n",
    "    cat_columns = [col for col in id_columns if col != 'id']\n",
    "\n",
    "    df_sales_train_melt = df_sales_train.melt(\n",
    "        id_vars=id_columns,\n",
    "        var_name='day_id',\n",
    "        value_name='sales'\n",
    "    )\n",
    "\n",
    "    df_sales_train_melt['sales'] = df_sales_train_melt['sales'].astype('int16')\n",
    "\n",
    "    return df_sales_train_melt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG [2020-07-06 11:03:09] root: Copying 0.0 MiB (deep=True)\n",
      "DEBUG [2020-07-06 11:03:09] root: Copying 0.0 MiB (deep=True)\n"
     ]
    }
   ],
   "source": [
    "sample_melt = melt_sales_series(sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG [2020-07-06 11:03:13] root: Copying 0.1 MiB (deep=True)\n",
      "DEBUG [2020-07-06 11:03:13] root: Copying 5.2 MiB (deep=True)\n",
      "DEBUG [2020-07-06 11:03:14] root: Copying 0.1 MiB (deep=True)\n",
      "DEBUG [2020-07-06 11:03:15] root: Copying 6.0 MiB (deep=True)\n"
     ]
    }
   ],
   "source": [
    "test_eq(n_days_total * 13, len(sample_melt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def extract_day_ids(df_sales_train_melt):\n",
    "    sales_columns = [f'd_{col}' for col in range(1, n_days_total+1)]\n",
    "    mapping = {col: int(col.split('_')[1]) for col in sales_columns}\n",
    "    df_sales_train_melt['day_id'] = df_sales_train_melt['day_id'].map(mapping)\n",
    "\n",
    "    import datetime\n",
    "    d_1_date = pd.to_datetime('2011-01-29')\n",
    "    mapping = {day:(d_1_date + datetime.timedelta(days=day-1)) for day in range(1, n_days_total+1)}\n",
    "    df_sales_train_melt['day_date'] = df_sales_train_melt['day_id'].map(mapping)\n",
    "\n",
    "    mapping = {day:str((d_1_date + datetime.timedelta(days=day-1)).date()) for day in range(1, n_days_total+1)}\n",
    "    # gonna need it for joining with calendars & stuff\n",
    "    df_sales_train_melt['day_date_str'] = df_sales_train_melt['day_id'].map(mapping)\n",
    "\n",
    "    df_sales_train_melt['day_id'] = df_sales_train_melt['day_id'].astype('int16')\n",
    "    df_sales_train_melt['month_id'] = df_sales_train_melt['day_date'].dt.month.astype('uint8')\n",
    "\n",
    "    return df_sales_train_melt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG [2020-07-06 11:03:15] root: Copying 0.0 MiB (deep=True)\n",
      "DEBUG [2020-07-06 11:03:15] root: Copying 0.0 MiB (deep=True)\n",
      "DEBUG [2020-07-06 11:03:15] root: Copying 0.0 MiB (deep=True)\n",
      "DEBUG [2020-07-06 11:03:15] root: Copying 0.0 MiB (deep=True)\n",
      "DEBUG [2020-07-06 11:03:15] root: Copying 0.0 MiB (deep=True)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Index(['id', 'item_id', 'dept_id', 'cat_id', 'store_id', 'state_id', 'day_id',\n",
       "       'sales', 'day_date', 'day_date_str', 'month_id'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_melt = extract_day_ids(sample_melt)\n",
    "sample_melt.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG [2020-07-06 11:03:19] root: Copying 0.1 MiB (deep=True)\n",
      "DEBUG [2020-07-06 11:03:19] root: Copying 5.2 MiB (deep=True)\n",
      "DEBUG [2020-07-06 11:03:19] root: Copying 5.1 MiB (deep=True)\n",
      "DEBUG [2020-07-06 11:03:19] root: Copying 4.5 MiB (deep=True)\n",
      "DEBUG [2020-07-06 11:03:19] root: Copying 4.6 MiB (deep=True)\n",
      "DEBUG [2020-07-06 11:03:19] root: Copying 5.3 MiB (deep=True)\n",
      "DEBUG [2020-07-06 11:03:19] root: Copying 5.3 MiB (deep=True)\n",
      "DEBUG [2020-07-06 11:03:20] root: Copying 0.1 MiB (deep=True)\n",
      "DEBUG [2020-07-06 11:03:20] root: Copying 6.0 MiB (deep=True)\n",
      "DEBUG [2020-07-06 11:03:20] root: Copying 5.9 MiB (deep=True)\n",
      "DEBUG [2020-07-06 11:03:20] root: Copying 5.3 MiB (deep=True)\n",
      "DEBUG [2020-07-06 11:03:21] root: Copying 5.4 MiB (deep=True)\n",
      "DEBUG [2020-07-06 11:03:21] root: Copying 6.2 MiB (deep=True)\n",
      "DEBUG [2020-07-06 11:03:21] root: Copying 6.1 MiB (deep=True)\n"
     ]
    }
   ],
   "source": [
    "test_eq(n_days_total * 13, len(sample_melt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG [2020-07-06 11:03:24] root: Copying 0.1 MiB (deep=True)\n",
      "DEBUG [2020-07-06 11:03:24] root: Copying 6.0 MiB (deep=True)\n",
      "DEBUG [2020-07-06 11:03:24] root: Copying 5.9 MiB (deep=True)\n",
      "DEBUG [2020-07-06 11:03:24] root: Copying 5.3 MiB (deep=True)\n",
      "DEBUG [2020-07-06 11:03:24] root: Copying 5.4 MiB (deep=True)\n",
      "DEBUG [2020-07-06 11:03:24] root: Copying 6.2 MiB (deep=True)\n",
      "DEBUG [2020-07-06 11:03:24] root: Copying 6.1 MiB (deep=True)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>dept_id</th>\n",
       "      <th>cat_id</th>\n",
       "      <th>store_id</th>\n",
       "      <th>state_id</th>\n",
       "      <th>day_id</th>\n",
       "      <th>sales</th>\n",
       "      <th>day_date</th>\n",
       "      <th>day_date_str</th>\n",
       "      <th>month_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>FOODS_3_727_TX_1_validation</td>\n",
       "      <td>FOODS_3_727</td>\n",
       "      <td>FOODS_3</td>\n",
       "      <td>FOODS</td>\n",
       "      <td>TX_1</td>\n",
       "      <td>TX</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2011-01-29</td>\n",
       "      <td>2011-01-29</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            id      item_id  dept_id cat_id store_id state_id  \\\n",
       "0  FOODS_3_727_TX_1_validation  FOODS_3_727  FOODS_3  FOODS     TX_1       TX   \n",
       "\n",
       "   day_id  sales   day_date day_date_str  month_id  \n",
       "0       1      0 2011-01-29   2011-01-29         1  "
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first_row = sample_melt.head(1)\n",
    "first_row "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_in(['day_date', 'day_date_str', 'day_id', 'month_id'], first_row.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_eq('2011-01-29', first_row.loc[0, 'day_date_str'])\n",
    "test_eq(1,            first_row.loc[0, 'day_id'])\n",
    "test_eq(1,            first_row.loc[0, 'month_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def join_w_calendar(df_sales_train_melt):\n",
    "    df_calendar = pd.read_csv(f'{raw_dir}/calendar.csv')\n",
    "\n",
    "    df_calendar_melt = df_calendar.melt(\n",
    "        id_vars=['date', 'wm_yr_wk', 'weekday', 'wday', 'year', 'd',\n",
    "                'event_name_1', 'event_name_2', 'event_type_1', 'event_type_2'],\n",
    "        value_name='snap_flag',\n",
    "        var_name='state_id',\n",
    "        value_vars=['snap_CA', 'snap_TX', 'snap_WI']\n",
    "    )\n",
    "    df_calendar_melt['snap_flag'] = df_calendar_melt['snap_flag'].astype('uint8')\n",
    "    df_calendar_melt['state_id'] = df_calendar_melt['state_id'].str.split('_').str[1]\n",
    "\n",
    "    df_sales_train_melt =  df_sales_train_melt.merge(\n",
    "        df_calendar_melt[['date', 'state_id', 'wm_yr_wk', 'snap_flag']],\n",
    "        left_on=['day_date_str', 'state_id'], right_on=['date', 'state_id'],\n",
    "#  TODO: dask does not seem to support these       validate='many_to_one'\n",
    "        )\n",
    "\n",
    "    df_sales_train_melt['wm_yr_wk'] = df_sales_train_melt['wm_yr_wk'].astype('int16')\n",
    "    return df_sales_train_melt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG [2020-07-06 11:06:28] root: Copying 0.0 MiB (deep=True)\n",
      "DEBUG [2020-07-06 11:06:29] root: Copying 0.0 MiB (deep=True)\n"
     ]
    }
   ],
   "source": [
    "sample_melt = join_w_calendar(sample_melt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG [2020-07-06 11:06:50] root: Copying 0.1 MiB (deep=True)\n",
      "DEBUG [2020-07-06 11:06:50] root: Copying 6.0 MiB (deep=True)\n",
      "DEBUG [2020-07-06 11:06:50] root: Copying 5.9 MiB (deep=True)\n",
      "DEBUG [2020-07-06 11:06:50] root: Copying 5.3 MiB (deep=True)\n",
      "DEBUG [2020-07-06 11:06:50] root: Copying 5.4 MiB (deep=True)\n",
      "DEBUG [2020-07-06 11:06:50] root: Copying 6.2 MiB (deep=True)\n",
      "DEBUG [2020-07-06 11:06:50] root: Copying 6.1 MiB (deep=True)\n",
      "DEBUG [2020-07-06 11:06:50] root: Copying 0.8 MiB (deep=True)\n",
      "DEBUG [2020-07-06 11:06:51] root: Copying 7.2 MiB (deep=True)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>dept_id</th>\n",
       "      <th>cat_id</th>\n",
       "      <th>store_id</th>\n",
       "      <th>state_id</th>\n",
       "      <th>day_id</th>\n",
       "      <th>sales</th>\n",
       "      <th>day_date</th>\n",
       "      <th>day_date_str</th>\n",
       "      <th>month_id</th>\n",
       "      <th>date</th>\n",
       "      <th>wm_yr_wk</th>\n",
       "      <th>snap_flag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>FOODS_3_727_TX_1_validation</td>\n",
       "      <td>FOODS_3_727</td>\n",
       "      <td>FOODS_3</td>\n",
       "      <td>FOODS</td>\n",
       "      <td>TX_1</td>\n",
       "      <td>TX</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2011-01-29</td>\n",
       "      <td>2011-01-29</td>\n",
       "      <td>1</td>\n",
       "      <td>2011-01-29</td>\n",
       "      <td>11101</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            id      item_id  dept_id cat_id store_id state_id  \\\n",
       "0  FOODS_3_727_TX_1_validation  FOODS_3_727  FOODS_3  FOODS     TX_1       TX   \n",
       "\n",
       "   day_id  sales   day_date day_date_str  month_id        date  wm_yr_wk  \\\n",
       "0       1      0 2011-01-29   2011-01-29         1  2011-01-29     11101   \n",
       "\n",
       "   snap_flag  \n",
       "0          0  "
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_melt.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: test_not_in ('date') == dup of day_date_str\n",
    "test_in(['wm_yr_wk', 'snap_flag'], sample_melt.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def join_w_prices(partition):\n",
    "    df_prices = pd.read_csv(f'{raw_dir}/sell_prices.csv')\n",
    "    partition = partition.merge(\n",
    "        df_prices,\n",
    "        on=['store_id', 'item_id', 'wm_yr_wk'],\n",
    "        how='left'\n",
    "    )\n",
    "    partition['sell_price'] = partition['sell_price'].astype('float32')\n",
    "    partition['sales_dollars'] = (partition['sales'] * partition['sell_price']).astype('float32')\n",
    "    partition = partition.fillna({'sales_dollars': 0}\n",
    "    # TODO: doesn't seem to be supported by dask, inplace=True\n",
    "    )\n",
    "    return partition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG [2020-07-06 11:10:07] root: Copying 0.0 MiB (deep=True)\n",
      "DEBUG [2020-07-06 11:10:07] root: Copying 0.0 MiB (deep=True)\n",
      "DEBUG [2020-07-06 11:10:07] root: Copying 0.0 MiB (deep=True)\n",
      "DEBUG [2020-07-06 11:10:07] root: Copying 0.0 MiB (deep=True)\n"
     ]
    }
   ],
   "source": [
    "sample_melt = join_w_prices(sample_melt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG [2020-07-06 11:10:14] root: Copying 0.1 MiB (deep=True)\n",
      "DEBUG [2020-07-06 11:10:14] root: Copying 6.0 MiB (deep=True)\n",
      "DEBUG [2020-07-06 11:10:14] root: Copying 5.9 MiB (deep=True)\n",
      "DEBUG [2020-07-06 11:10:14] root: Copying 5.3 MiB (deep=True)\n",
      "DEBUG [2020-07-06 11:10:14] root: Copying 5.4 MiB (deep=True)\n",
      "DEBUG [2020-07-06 11:10:14] root: Copying 6.2 MiB (deep=True)\n",
      "DEBUG [2020-07-06 11:10:14] root: Copying 6.1 MiB (deep=True)\n",
      "DEBUG [2020-07-06 11:10:14] root: Copying 0.8 MiB (deep=True)\n",
      "DEBUG [2020-07-06 11:10:15] root: Copying 7.2 MiB (deep=True)\n",
      "DEBUG [2020-07-06 11:10:23] root: Copying 957.5 MiB (deep=True)\n",
      "DEBUG [2020-07-06 11:10:25] root: Copying 7.2 MiB (deep=True)\n",
      "DEBUG [2020-07-06 11:10:25] root: Copying 7.2 MiB (deep=True)\n",
      "DEBUG [2020-07-06 11:10:25] root: Copying 7.2 MiB (deep=True)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>dept_id</th>\n",
       "      <th>cat_id</th>\n",
       "      <th>store_id</th>\n",
       "      <th>state_id</th>\n",
       "      <th>day_id</th>\n",
       "      <th>sales</th>\n",
       "      <th>day_date</th>\n",
       "      <th>day_date_str</th>\n",
       "      <th>month_id</th>\n",
       "      <th>date</th>\n",
       "      <th>wm_yr_wk</th>\n",
       "      <th>snap_flag</th>\n",
       "      <th>sell_price</th>\n",
       "      <th>sales_dollars</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>FOODS_3_727_TX_1_validation</td>\n",
       "      <td>FOODS_3_727</td>\n",
       "      <td>FOODS_3</td>\n",
       "      <td>FOODS</td>\n",
       "      <td>TX_1</td>\n",
       "      <td>TX</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2011-01-29</td>\n",
       "      <td>2011-01-29</td>\n",
       "      <td>1</td>\n",
       "      <td>2011-01-29</td>\n",
       "      <td>11101</td>\n",
       "      <td>0</td>\n",
       "      <td>3.98</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            id      item_id  dept_id cat_id store_id state_id  \\\n",
       "0  FOODS_3_727_TX_1_validation  FOODS_3_727  FOODS_3  FOODS     TX_1       TX   \n",
       "\n",
       "   day_id  sales   day_date day_date_str  month_id        date  wm_yr_wk  \\\n",
       "0       1      0 2011-01-29   2011-01-29         1  2011-01-29     11101   \n",
       "\n",
       "   snap_flag  sell_price  sales_dollars  \n",
       "0          0        3.98            0.0  "
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_melt.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_in(['sell_price', 'sales_dollars'], sample_melt.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
